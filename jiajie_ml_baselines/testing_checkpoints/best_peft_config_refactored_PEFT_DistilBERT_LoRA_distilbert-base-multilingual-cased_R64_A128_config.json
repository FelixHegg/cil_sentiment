{
    "model_type": "peft_bert_mlp",
    "run_name": "refactored_PEFT_DistilBERT_LoRA",
    "num_classes": 3,
    "validation_split": 0.15,
    "random_state": 42,
    "batch_size": 256,
    "hf_base_model_name": "distilbert-base-multilingual-cased",
    "max_seq_len": 128,
    "peft_method": "LoRA",
    "lora_rank": 64,
    "lora_alpha": 128,
    "lora_target_modules": [
        "q_lin",
        "v_lin",
        "k_lin",
        "out_lin"
    ],
    "lora_dropout": 0.1,
    "lora_bias": "none",
    "classifier_mlp_hidden_dims": [
        128,
        64
    ],
    "classifier_mlp_dropout": 0.5,
    "learning_rate": 0.0001,
    "weight_decay": 0.0001,
    "optimizer_type": "AdamW",
    "epochs": 50,
    "early_stopping_patience": 5,
    "lr_scheduler_patience": 3,
    "lr_scheduler_factor": 0.2,
    "hf_tokenizer_name": "distilbert-base-multilingual-cased",
    "max_seq_len_used": 128,
    "label_encoder_classes": [
        "negative",
        "neutral",
        "positive"
    ],
    "index_to_mae_label_map": {
        "0": -1,
        "1": 0,
        "2": 1
    }
}